{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, MaxPool2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import preprocess_input\n",
    "import splitfolders\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\batch-pc\\Documents\\Data science ft\\ds_ft_sep_22\\3-Machine_Learning\\Proyecto_ML\\Data\\book-covers'\n",
    "filenames = os.listdir(PATH)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename\n",
    "    categories.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Art-Photography',\n",
       " 'Biography',\n",
       " 'Business-Finance-Law',\n",
       " 'Childrens-Books',\n",
       " 'Computing',\n",
       " 'Crafts-Hobbies',\n",
       " 'Crime-Thriller',\n",
       " 'Dictionaries-Languages',\n",
       " 'Entertainment',\n",
       " 'Food-Drink',\n",
       " 'Graphic-Novels-Anime-Manga',\n",
       " 'Health',\n",
       " 'History-Archaeology',\n",
       " 'Home-Garden',\n",
       " 'Humour',\n",
       " 'Medical',\n",
       " 'Mind-Body-Spirit',\n",
       " 'Natural-History',\n",
       " 'Personal-Development',\n",
       " 'Poetry-Drama',\n",
       " 'Reference',\n",
       " 'Religion',\n",
       " 'Romance',\n",
       " 'Science-Fiction-Fantasy-Horror',\n",
       " 'Science-Geography',\n",
       " 'Society-Social-Sciences',\n",
       " 'Sport',\n",
       " 'Stationery',\n",
       " 'Teaching-Resources-Education',\n",
       " 'Technology-Engineering',\n",
       " 'Teen-Young-Adult',\n",
       " 'Transport',\n",
       " 'Travel-Holiday-Guides']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Art-Photography': 0,\n",
       " 'Biography': 1,\n",
       " 'Business-Finance-Law': 2,\n",
       " 'Childrens-Books': 3,\n",
       " 'Computing': 4,\n",
       " 'Crafts-Hobbies': 5,\n",
       " 'Crime-Thriller': 6,\n",
       " 'Dictionaries-Languages': 7,\n",
       " 'Entertainment': 8,\n",
       " 'Food-Drink': 9,\n",
       " 'Graphic-Novels-Anime-Manga': 10,\n",
       " 'Health': 11,\n",
       " 'History-Archaeology': 12,\n",
       " 'Home-Garden': 13,\n",
       " 'Humour': 14,\n",
       " 'Medical': 15,\n",
       " 'Mind-Body-Spirit': 16,\n",
       " 'Natural-History': 17,\n",
       " 'Personal-Development': 18,\n",
       " 'Poetry-Drama': 19,\n",
       " 'Reference': 20,\n",
       " 'Religion': 21,\n",
       " 'Romance': 22,\n",
       " 'Science-Fiction-Fantasy-Horror': 23,\n",
       " 'Science-Geography': 24,\n",
       " 'Society-Social-Sciences': 25,\n",
       " 'Sport': 26,\n",
       " 'Stationery': 27,\n",
       " 'Teaching-Resources-Education': 28,\n",
       " 'Technology-Engineering': 29,\n",
       " 'Teen-Young-Adult': 30,\n",
       " 'Transport': 31,\n",
       " 'Travel-Holiday-Guides': 32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_names_label = {class_name:i for i ,class_name in enumerate(categories)}\n",
    "categories_names_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 32614 files [06:21, 85.49 files/s] \n"
     ]
    }
   ],
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(r\".\\Data\\book-covers\", output=r\".\\Data\\train_test\",\n",
    "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "\u001b[1;32mdef\u001b[0m \u001b[0mcopy_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"\n",
      "    Copies the files from the input folder to the output folder\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy2\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# get the last part within the file\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfull_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mprog_bar\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mprog_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcopy_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcopy_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\batch-pc\\anaconda3\\envs\\bootcamp_core\\lib\\site-packages\\splitfolders\\split.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "splitfolders.copy_files??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26050 images belonging to 33 classes.\n",
      "Found 3249 images belonging to 33 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True\n",
    "                                  )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('Data/train_test/train/', class_mode='categorical', \n",
    "                                                    batch_size = batch_size, target_size=(image_size,image_size), \n",
    "                                                    shuffle=True, seed=42)\n",
    "validation_generator = train_datagen.flow_from_directory('Data/train_test/val/', class_mode='categorical',\n",
    "                                                        batch_size = batch_size, target_size=(image_size,image_size),\n",
    "                                                        shuffle=True, seed=42)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 2048)              20861480  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 33)                16929     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,697,737\n",
      "Trainable params: 6,836,257\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model = tf.keras.applications.xception.Xception(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling='avg',\n",
    "    classes=33,\n",
    "    classifier_activation='softmax'\n",
    "    )\n",
    "tf.random.set_seed(73)\n",
    "model = Sequential()\n",
    "model.add(xception_model)\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(units=2048, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(33, activation='softmax'))\n",
    "model.layers[0].trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save_best = ModelCheckpoint(\n",
    "filepath = 'best_model.hdf5',\n",
    "verbose=1, save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\batch-pc\\AppData\\Local\\Temp\\ipykernel_19416\\2639075760.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, validation_data = validation_generator,\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 3.04221, saving model to best_model.hdf5\n",
      "407/407 - 264s - loss: 3.2305 - accuracy: 0.1215 - val_loss: 3.0422 - val_accuracy: 0.1741 - 264s/epoch - 648ms/step\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 2: val_loss improved from 3.04221 to 2.96013, saving model to best_model.hdf5\n",
      "407/407 - 262s - loss: 3.0020 - accuracy: 0.1799 - val_loss: 2.9601 - val_accuracy: 0.1822 - 262s/epoch - 644ms/step\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 3: val_loss improved from 2.96013 to 2.91665, saving model to best_model.hdf5\n",
      "407/407 - 282s - loss: 2.9210 - accuracy: 0.1948 - val_loss: 2.9166 - val_accuracy: 0.2037 - 282s/epoch - 693ms/step\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 4: val_loss improved from 2.91665 to 2.91005, saving model to best_model.hdf5\n",
      "407/407 - 191s - loss: 2.8551 - accuracy: 0.2087 - val_loss: 2.9101 - val_accuracy: 0.1981 - 191s/epoch - 470ms/step\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 5: val_loss improved from 2.91005 to 2.87361, saving model to best_model.hdf5\n",
      "407/407 - 228s - loss: 2.7872 - accuracy: 0.2257 - val_loss: 2.8736 - val_accuracy: 0.2103 - 228s/epoch - 559ms/step\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 6: val_loss improved from 2.87361 to 2.85654, saving model to best_model.hdf5\n",
      "407/407 - 196s - loss: 2.7263 - accuracy: 0.2356 - val_loss: 2.8565 - val_accuracy: 0.2116 - 196s/epoch - 482ms/step\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 7: val_loss improved from 2.85654 to 2.84091, saving model to best_model.hdf5\n",
      "407/407 - 186s - loss: 2.6726 - accuracy: 0.2472 - val_loss: 2.8409 - val_accuracy: 0.2119 - 186s/epoch - 456ms/step\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 8: val_loss improved from 2.84091 to 2.81847, saving model to best_model.hdf5\n",
      "407/407 - 190s - loss: 2.6146 - accuracy: 0.2594 - val_loss: 2.8185 - val_accuracy: 0.2244 - 190s/epoch - 467ms/step\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 9: val_loss did not improve from 2.81847\n",
      "407/407 - 299s - loss: 2.5528 - accuracy: 0.2731 - val_loss: 2.8410 - val_accuracy: 0.2106 - 299s/epoch - 735ms/step\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 10: val_loss did not improve from 2.81847\n",
      "407/407 - 310s - loss: 2.5014 - accuracy: 0.2829 - val_loss: 2.8647 - val_accuracy: 0.2066 - 310s/epoch - 763ms/step\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 11: val_loss did not improve from 2.81847\n",
      "407/407 - 310s - loss: 2.4381 - accuracy: 0.2990 - val_loss: 2.8678 - val_accuracy: 0.2013 - 310s/epoch - 761ms/step\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 12: val_loss did not improve from 2.81847\n",
      "407/407 - 313s - loss: 2.3794 - accuracy: 0.3096 - val_loss: 2.8544 - val_accuracy: 0.2009 - 313s/epoch - 769ms/step\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 13: val_loss did not improve from 2.81847\n",
      "407/407 - 309s - loss: 2.3225 - accuracy: 0.3205 - val_loss: 2.8984 - val_accuracy: 0.2153 - 309s/epoch - 760ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, validation_data = validation_generator,\\\n",
    "                         validation_steps = validation_generator.samples // batch_size, epochs = epochs, callbacks=[save_best,early_stopping], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacar el top 3 de categorias y comprobar la accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacer un transformer con imagenes y titulos para determinar el genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('bootcamp_core')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee25a2d1a1f270354bc61de82ab2095fe8502aab0e92b4ab7eba41260aafaf03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
